custom: {}
chart:
  name: jupyterhub
  version: 0.8.2
hub:
  service:
    type: ClusterIP
    annotations: {}
    ports:
      nodePort:
    loadBalancerIP:
  baseUrl:  /splicejupyter/
  cookieSecret:
  publicURL:
  uid: 1000
  fsGid: 1000
  nodeSelector: {}
  concurrentSpawnLimit: 64
  consecutiveFailureLimit: 5
  activeServerLimit:
  deploymentStrategy:
    # sqlite-pvc backed hub requires Recreate strategy to work
    type: Recreate
    # This is required for upgrading to work
    rollingUpdate:
  db:
    type: sqlite-pvc
    upgrade:
    pvc:
      annotations: {}
      selector: {}
      accessModes:
        - ReadWriteOnce
      storage: 1Gi
      subPath:
      storageClassName:
    url:
    password:
  labels: {}
  annotations: {}
  extraConfig:
    AuthConfig: |
      import sys
      sys.path.append('/srv')
      from Authentication import SpliceAuthenticator
      c.JupyterHub.authenticator_class = SpliceAuthenticator
      c.Authenticator.enable_auth_state = True
      c.Authenticator.admin_users = {'splice'}
    UserConfig: |
      c.JupyterHub.active_server_limit=10
  extraConfigMap: {}
  extraEnv: {}
  extraContainers: []
  extraVolumes: []
  extraVolumeMounts: []
  image:
    name: splicemachine/sm_k8_jupyterhub
    tag: '0.0.14'
  resources:
    requests:
      cpu: 200m
      memory: 512Mi
  services: {}
  imagePullPolicy: IfNotPresent
  imagePullSecret:
    enabled: false
    registry:
    username:
    email:
    password:
  pdb:
    enabled: true
    minAvailable: 1
    maxUnavailable: 1
  networkPolicy:
    enabled: false
    egress:
      - to:
          - ipBlock:
              cidr: 0.0.0.0/0
  allowNamedServers: false


rbac:
  enabled: true


proxy:
  secretToken: '07c4cf87cd14c6b173dcf51077020c4377eb5749eb0a7190c884409b78a0ae6a'
  service:
    type: ClusterIP
    labels: {}
    annotations: {}
    nodePorts:
      http:
      https:
    loadBalancerIP:
  chp:
    image:
      name: jupyterhub/configurable-http-proxy
      tag: 3.0.0
      pullPolicy: IfNotPresent
    resources:
      requests:
        cpu: 200m
        memory: 512Mi
  nginx:
    image:
      name: quay.io/kubernetes-ingress-controller/nginx-ingress-controller
      tag: 0.15.0
      pullPolicy: IfNotPresent
    proxyBodySize: 64m
    resources: {}
  lego:
    image:
      name: jetstack/kube-lego
      tag: 0.1.7
      pullPolicy: IfNotPresent
    resources: {}
  labels: {}
  nodeSelector: {}
  pdb:
    enabled: true
    minAvailable: 1
    maxUnavailable: 1
  https:
    enabled: false
    type: letsencrypt
    #type: letsencrypt, manual, offload, secret
    letsencrypt:
      contactEmail: ''
    manual:
      key:
      cert:
    secret:
      name: ''
      key: tls.key
      crt: tls.crt
    hosts: []
  networkPolicy:
    enabled: false
    egress:
      - to:
          - ipBlock:
              cidr: 0.0.0.0/0


auth:
  type: dummy
  whitelist:
    users:
  admin:
    access: true
    users:
  dummy:
    password:
  ldap:
    dn:
      search: {}
      user: {}
    user: {}
  state:
    enabled: true
    cryptoKey: 'ed43efddb2954cfeaa313795314574e3a588284f60ce690144da776cc08567e8'


singleuser:
  extraTolerations: []
  nodeSelector: {}
  extraNodeAffinity:
    required: []
    preferred: []
  extraPodAffinity:
    required: []
    preferred: []
  extraPodAntiAffinity:
    required: []
    preferred: []
  networkTools:
    image:
      name: jupyterhub/k8s-network-tools
      tag: '0.8.2'
  cloudMetadata:
    enabled: false
    ip: 169.254.169.254
  networkPolicy:
    enabled: false
    egress:
    # Required egress is handled by other rules so it's safe to modify this
      - to:
          - ipBlock:
              cidr: 0.0.0.0/0
              except:
                - 169.254.169.254/32
  events: true
  extraAnnotations: {}
  extraLabels:
    hub.jupyter.org/network-access-hub: 'true'
  extraEnv:
    SPARK_DOCKER_IMAGE: "splicemachine/sm_k8_spark-3.0.0:0.0.64"
    SPARK_EXECUTOR_COUNT: "2"
    JUPYTER_NOTEBOOK_VERSION: 0.0.19-cloud
    JUPYTER_SPARK_NODE_SELECTOR: "db"
  lifecycleHooks:
  initContainers: []
  extraContainers: []
  uid: 1000
  fsGid: 100
  serviceAccountName: spark
  storage:
    type: dynamic
    extraLabels: {}
    extraVolumes:
      - name: hbase-config
        configMap:
          name: dev-splice-hbase-config
      - name: hdfs-config
        configMap:
          name: dev-splice-hadoop-config
    extraVolumeMounts:
      - name: hbase-config
        mountPath: /tmp/hbase-config
      - name: hdfs-config
        mountPath: /tmp/hdfs-config
    static:
      pvcName:
      subPath: '{username}'
    capacity: 10Gi
    homeMountPath: /home/jovyan
    dynamic:
      storageClass:
      pvcNameTemplate: claim-{username}{servername}
      volumeNameTemplate: volume-{username}{servername}
      storageAccessModes: [ReadWriteOnce]
  image:
    name: splicemachine/sm_k8_jupyter_allspark-3.0.0:0.0.54
    pullPolicy: IfNotPresent
  imagePullSecret:
    enabled: false
    registry:
    username:
    email:
    password:
  startTimeout: 300
  cpu:
    limit:
    guarantee:
  memory:
    limit:
    guarantee: 1G
  extraResource:
    limits: {}
    guarantees: {}
  cmd: jupyterhub-singleuser
  defaultUrl:


scheduling:
  userScheduler:
    enabled: false
    replicas: 1
    logLevel: 4
    image:
      name: gcr.io/google_containers/kube-scheduler-amd64
      tag: v1.11.2
    nodeSelector: {}
    pdb:
      enabled: true
      minAvailable: 1
      maxUnavailable: 1
    resources:
      requests:
        cpu: 50m
        memory: 256Mi
  podPriority:
    enabled: false
    globalDefault: false
    defaultPriority: 0
    userPlaceholderPriority: -10
  userPlaceholder:
    enabled: true
    replicas: 0
  corePods:
    nodeAffinity:
      matchNodePurpose: prefer
  userPods:
    nodeAffinity:
      matchNodePurpose: prefer


prePuller:
  hook:
    enabled: false
    image:
      name: jupyterhub/k8s-image-awaiter
      tag: '0.8.2'
  continuous:
    enabled: false
  extraImages: {}
  pause:
    image:
      name: gcr.io/google_containers/pause
      tag: '3.0'


ingress:
  enabled: true
  annotations:
    kubernetes.io/ingress.class: nginx-core
    kubernetes.io/tls-acme: "true"
    nginx.ingress.kubernetes.io/proxy-body-size: "0"
    #nginx-nonadmin
  hosts:
    - REPLACE_INGRESS_DOMAIN
  pathSuffix: /splicejupyter/
  tls:
    - hosts:
      - REPLACE_INGRESS_DOMAIN
      secretName: REPLACE_CERTIFICATE


cull:
  enabled: true
  users: false
  timeout: 3600
  every: 600
  concurrency: 10
  maxAge: 0


debug:
  enabled: false

## ------------------------------------------------------------------------------
## Global values affecting all sub-charts:
## ------------------------------------------------------------------------------
global:

  #
  # This should be the dcosAppId that comes from cloud manager.  It
  # allows us to tie a database back to database record in CM.
  #
  frameworkId: myaccount-mycluster-866ab7178f
  dnsprefix: "test"

  splice:
    password: admin
    user: splice

  mlflow:
    port:
      mlflow: 5001

  timezoneFlag: "UTC"

  nodeSelector:
    enabled: true
    db: db
    core: core
    meta: meta
